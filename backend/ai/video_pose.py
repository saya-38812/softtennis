import os
import logging
import numpy as np
import cv2

from .video_pose_analyzer import extract_pose_landmarks
from .normalize_pose import normalize_pose

from .angle_utils import (
    calculate_shoulder_angle,
    calculate_elbow_angle,
    calculate_wrist_angle,
    calculate_waist_rotation,
    calculate_body_sway,
    calculate_impact_height,
    calculate_impact_forward,
    calculate_toss_sync,
    calculate_impact_left_right,
    calculate_weight_left_right,
)

logging.basicConfig(level=logging.INFO)

# ================================
# focusè¾æ›¸ï¼ˆãƒˆãƒƒãƒ—1ã ã‘ï¼‰
# ================================

FOCUS_LABELS = {
    "elbow_angle": "è‚˜ã®è§’åº¦",
    "impact_height": "æ‰“ç‚¹ã®é«˜ã•",
    "shoulder_angle": "è‚©ã®é–‹ã",
    "waist_rotation": "è…°ã®å›è»¢",
    "body_sway": "ä½“è»¸ã®ãƒ–ãƒ¬",
    "impact_forward": "æ‰“ç‚¹ã®å‰å¾Œä½ç½®",
    "toss_sync": "ãƒˆã‚¹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°",
    "impact_left_right": "æ‰“ç‚¹ã®å·¦å³ä½ç½®",
    "weight_left_right": "å·¦å³ã®ä½“é‡ãƒãƒ©ãƒ³ã‚¹",
}

FOCUS_MESSAGES = {
    "elbow_angle": "è‚˜ãŒæ›²ãŒã‚Šã™ãã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã§ä¼¸ã°ã—ã¾ã—ã‚‡ã†ã€‚",
    "impact_height": "æ‰“ç‚¹ãŒä½ã„ã§ã™ã€‚ã‚‚ã£ã¨é«˜ã„ä½ç½®ã§å½“ã¦ã¾ã—ã‚‡ã†ã€‚",
    "shoulder_angle": "ä½“ãŒé–‹ãã™ãã¦ã„ã¾ã™ã€‚æ¨ªå‘ãã‚’æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚",
    "waist_rotation": "è…°ã®å›è»¢ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚ä¸‹åŠèº«ã‹ã‚‰å›ã—ã¾ã—ã‚‡ã†ã€‚",
    "body_sway": "ä½“ã®è»¸ãŒãƒ–ãƒ¬ã¦ã„ã¾ã™ã€‚é ­ã‚’å®‰å®šã•ã›ã¾ã—ã‚‡ã†ã€‚",
    "impact_forward": "æ‰“ç‚¹ãŒå¾Œã‚ã§ã™ã€‚å°‘ã—å‰ã§æ‰ãˆã¾ã—ã‚‡ã†ã€‚",
    "toss_sync": "ãƒˆã‚¹ã¨ã‚¹ã‚¤ãƒ³ã‚°ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒãšã‚Œã¦ã„ã¾ã™ã€‚",
    "impact_left_right": "æ‰“ç‚¹ãŒå·¦å³ã«ãšã‚Œã¦ã„ã¾ã™ã€‚ä½“ã®æ­£é¢ã§å½“ã¦ã¾ã—ã‚‡ã†ã€‚",
    "weight_left_right": "ä½“é‡ãƒãƒ©ãƒ³ã‚¹ãŒå´©ã‚Œã¦ã„ã¾ã™ã€‚è»¸è¶³ã‚’æ„è­˜ã—ã¾ã—ã‚‡ã†ã€‚",
}

FOCUS_PRIORITY = list(FOCUS_LABELS.keys())

# èµ¤ä¸¸ã‚’ã¤ã‘ã‚‹MediaPipe landmarkï¼ˆå³åˆ©ãï¼‰
FOCUS_MARK_LANDMARK = {
    "elbow_angle": 14,
    "impact_height": 16,
    "impact_forward": 16,
    "impact_left_right": 16,
    "toss_sync": 16,
    "shoulder_angle": 12,
    "waist_rotation": 24,
    "body_sway": 24,
    "weight_left_right": 26,
}

# ================================
# Utility
# ================================

def pick_focus(weakness):
    """weaknessã®ä¸­ã§æœ€å„ªå…ˆã‚’1ã¤é¸ã¶"""
    for k in FOCUS_PRIORITY:
        if weakness.get(k) != "ok":
            return k
    return "impact_height"


def to_pixel(p, w, h):
    """0-1åº§æ¨™ â†’ ãƒ”ã‚¯ã‚»ãƒ«å¤‰æ›"""
    return int(p[0] * w), int(p[1] * h)


def save_frame(video_path, idx, out_path):
    """æŒ‡å®šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”»åƒã¨ã—ã¦ä¿å­˜"""
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)

    ret, frame = cap.read()
    cap.release()

    if not ret:
        logging.warning("ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return None

    cv2.imwrite(out_path, frame)
    return frame


def smooth(x, w=5):
    """ç§»å‹•å¹³å‡ã§ãƒã‚¤ã‚ºé™¤å»"""
    return np.convolve(x, np.ones(w) / w, mode="same")


# ================================
# æœ€å¼·ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¨å®šï¼ˆæœ€é«˜ç‚¹â†’ä¸‹é™é–‹å§‹ï¼‰
# ================================

def detect_best_contact_frame(landmarks_3d):
    """
    ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¨å®šï¼š

    â‘ å³æ‰‹é¦–ãŒæœ€é«˜ç‚¹ã«ãªã‚‹
    â‘¡ãã“ã‹ã‚‰ä¸‹é™ã—å§‹ã‚ã‚‹ç¬é–“ãŒã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
    """

    n = len(landmarks_3d)
    if n < 15:
        return int(n * 0.7)

    WRIST = 16

    wrist_y = []
    for i in range(n):
        wrist_y.append(landmarks_3d[i][WRIST][1])

    wrist_y = smooth(np.array(wrist_y), 5)

    # â‘ æœ€é«˜ç‚¹ï¼ˆæœ€å°yï¼‰
    peak = int(np.argmin(wrist_y))

    # â‘¡ä¸‹é™é–‹å§‹ã‚’æ¢ã™
    search_end = min(n - 1, peak + 8)

    best = peak

    for i in range(peak + 1, search_end):
        diff = wrist_y[i] - wrist_y[i - 1]

        # ä¸Šæ˜‡â†’ä¸‹é™ã«åˆ‡ã‚Šæ›¿ã‚ã£ãŸç¬é–“
        if diff > 0:
            best = i
            break

    # ğŸ¯æ¥è§¦ã¯ãã®1ãƒ•ãƒ¬å¾ŒãŒå¤šã„
    best = min(n - 1, best + 1)

    return best


# ================================
# ãƒ¡ã‚¤ãƒ³è§£æ
# ================================

def analyze_video(file_path):
    BASE_DIR = os.path.dirname(__file__)
    success_path = os.path.join(BASE_DIR, "success.mp4")

    # éª¨æ ¼æŠ½å‡º
    success_3d = extract_pose_landmarks(success_path)
    target_3d = extract_pose_landmarks(file_path)

    success_seq = normalize_pose(success_3d)
    target_seq = normalize_pose(target_3d)

    if len(success_seq) == 0 or len(target_seq) == 0:
        return {
            "menu": ["åŸºæœ¬ãƒ•ã‚©ãƒ¼ãƒ ç·´ç¿’"],
            "ai_text": "è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ",
        }

    # ----------------
    # ã‚¹ã‚³ã‚¢è¨ˆç®—
    # ----------------
    dists = []
    for t in target_seq:
        d = np.linalg.norm(success_seq - t, axis=(1, 2))
        dists.append(np.min(d))

    score = int(max(0, min(100, 100 - np.mean(dists) * 28)))

    # ----------------
    # å…¨æŒ‡æ¨™è¨ˆç®—ï¼ˆæ®‹ã™ï¼‰
    # ----------------
    is_right = True

    shoulder_diff = np.mean(calculate_shoulder_angle(target_seq, is_right)) - np.mean(
        calculate_shoulder_angle(success_seq, is_right)
    )

    elbow_diff = np.mean(calculate_elbow_angle(target_seq, is_right)) - np.mean(
        calculate_elbow_angle(success_seq, is_right)
    )

    wrist_diff = np.mean(calculate_wrist_angle(target_seq, is_right)) - np.mean(
        calculate_wrist_angle(success_seq, is_right)
    )

    waist_rot_diff = np.mean(calculate_waist_rotation(target_seq, is_right)) - np.mean(
        calculate_waist_rotation(success_seq, is_right)
    )

    sway_diff = np.mean(calculate_body_sway(target_seq)) - np.mean(
        calculate_body_sway(success_seq)
    )

    impact_h_diff = np.mean(calculate_impact_height(target_seq, is_right)) - np.mean(
        calculate_impact_height(success_seq, is_right)
    )

    impact_f_diff = np.mean(calculate_impact_forward(target_seq, is_right)) - np.mean(
        calculate_impact_forward(success_seq, is_right)
    )

    toss_diff = np.mean(calculate_toss_sync(target_seq, is_right)) - np.mean(
        calculate_toss_sync(success_seq, is_right)
    )

    lr_diff = np.mean(calculate_impact_left_right(target_seq, is_right)) - np.mean(
        calculate_impact_left_right(success_seq, is_right)
    )

    weight_lr_diff = np.mean(calculate_weight_left_right(target_seq)) - np.mean(
        calculate_weight_left_right(success_seq)
    )

    # ----------------
    # weaknessåˆ¤å®š
    # ----------------
    weakness = {
        "elbow_angle": "too_bent" if elbow_diff < -20 else "ok",
        "impact_height": "low" if impact_h_diff < -0.15 else "ok",
        "shoulder_angle": "too_open" if shoulder_diff > 15 else "ok",
        "waist_rotation": "insufficient" if waist_rot_diff < -20 else "ok",
        "body_sway": "unstable" if sway_diff > 0.03 else "ok",
        "impact_forward": "too_back" if impact_f_diff < -0.1 else "ok",
        "toss_sync": "out_of_sync" if abs(toss_diff) > 0.2 else "ok",
        "impact_left_right": "unstable" if abs(lr_diff) > 0.05 else "ok",
        "weight_left_right": "unbalanced" if abs(weight_lr_diff) > 0.03 else "ok",
    }

    focus = pick_focus(weakness)

    # ----------------
    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼çŸ­ã1å€‹ã ã‘
    # ----------------
    menu = [f"{FOCUS_LABELS[focus]}ã‚’æ”¹å–„ã™ã‚‹ç´ æŒ¯ã‚Šç·´ç¿’"]

    # ----------------
    # ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆç”»åƒç”Ÿæˆ
    # ----------------
    out_dir = os.path.join(BASE_DIR, "..", "outputs")
    os.makedirs(out_dir, exist_ok=True)

    user_idx = detect_best_contact_frame(target_3d)
    ideal_idx = detect_best_contact_frame(success_3d)

    lid = FOCUS_MARK_LANDMARK[focus]

    cap = cv2.VideoCapture(file_path)
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    ux, uy = to_pixel(target_3d[user_idx][lid], w, h)
    ix, iy = to_pixel(success_3d[ideal_idx][lid], w, h)

    # ideal
    ideal_img = save_frame(success_path, ideal_idx, os.path.join(out_dir, "ideal.png"))
    if ideal_img is not None:
        cv2.circle(ideal_img, (ix, iy), 18, (0, 255, 0), -1)
        cv2.imwrite(os.path.join(out_dir, "ideal.png"), ideal_img)

    # user
    user_img = save_frame(file_path, user_idx, os.path.join(out_dir, "user.png"))
    if user_img is not None:
        cv2.circle(user_img, (ux, uy), 18, (0, 0, 255), -1)
        cv2.circle(user_img, (ix, iy), 18, (0, 255, 0), -1)
        cv2.arrowedLine(user_img, (ux, uy), (ix, iy), (255, 255, 255), 4)
        cv2.imwrite(os.path.join(out_dir, "user.png"), user_img)

    # ----------------
    # AIæ–‡ç« ï¼ˆçŸ­ãï¼‰
    # ----------------
    ai_text = f"æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã¯ã€Œ{FOCUS_LABELS[focus]}ã€ã§ã™ã€‚ã¾ãš1ã¤ã ã‘æ„è­˜ã—ã¾ã—ã‚‡ã†ï¼"

    return {
        "diagnosis": {
            "player": {"age": 13, "hand": "right", "serve_score": score},
            "weakness": weakness,
            "raw_values": {
                "elbow_angle_diff": float(elbow_diff),
                "impact_height_diff": float(impact_h_diff),
                "shoulder_angle_diff": float(shoulder_diff),
                "waist_rotation_diff": float(waist_rot_diff),
                "body_sway_diff": float(sway_diff),
                "impact_forward_diff": float(impact_f_diff),
                "toss_sync_diff": float(toss_diff),
                "impact_left_right_diff": float(lr_diff),
                "weight_left_right_diff": float(weight_lr_diff),
            },
        },
        "menu": menu,
        "ai_text": ai_text,
        "ideal_image": "/outputs/ideal.png",
        "user_image": "/outputs/user.png",
        "focus_label": FOCUS_LABELS[focus],
        "message": FOCUS_MESSAGES[focus],
    }
