import os
import logging
import numpy as np
import cv2

from .video_pose_analyzer import extract_pose_landmarks
from .normalize_pose import normalize_pose

from .angle_utils import (
    calculate_shoulder_angle,
    calculate_elbow_angle,
    calculate_wrist_angle,
    calculate_waist_rotation,
    calculate_body_sway,
    calculate_impact_height,
    calculate_impact_forward,
    calculate_toss_sync,
    calculate_impact_left_right,
    calculate_weight_left_right,
)

logging.basicConfig(level=logging.INFO)

# ================================
# ğŸ¯ãƒ¡ã‚¤ãƒ³æ”¹å–„ï¼ˆå¼·ãå‡ºã™3ã¤ï¼‰
# ================================

MAIN_FOCUS = ["impact_height", "elbow_angle", "body_sway"]

FOCUS_LABELS = {
    "impact_height": "æ‰“ç‚¹ã®é«˜ã•",
    "elbow_angle": "è‚˜ã®è§’åº¦",
    "body_sway": "ä½“è»¸ã®ãƒ–ãƒ¬",

    # å‚è€ƒæŒ‡æ¨™ï¼ˆè»½ãè¡¨ç¤ºï¼‰
    "shoulder_angle": "è‚©ã®é–‹ãï¼ˆå‚è€ƒï¼‰",
    "waist_rotation": "è…°ã®å›è»¢ï¼ˆå‚è€ƒï¼‰",
    "impact_forward": "æ‰“ç‚¹ã®å‰å¾Œï¼ˆå‚è€ƒï¼‰",
    "toss_sync": "ãƒˆã‚¹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆå‚è€ƒï¼‰",
    "impact_left_right": "æ‰“ç‚¹ã®å·¦å³ï¼ˆå‚è€ƒï¼‰",
    "weight_left_right": "ä½“é‡ãƒãƒ©ãƒ³ã‚¹ï¼ˆå‚è€ƒï¼‰",
}

FOCUS_MESSAGES = {
    "impact_height": "æ‰“ç‚¹ãŒä½ã„ã§ã™ã€‚ã‚‚ã£ã¨é«˜ã„ä½ç½®ã§å½“ã¦ã¾ã—ã‚‡ã†ã€‚",
    "elbow_angle": "è‚˜ãŒæ›²ãŒã‚Šã™ãã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã§ä¼¸ã°ã—ã¾ã—ã‚‡ã†ã€‚",
    "body_sway": "ä½“ã®è»¸ãŒãƒ–ãƒ¬ã¦ã„ã¾ã™ã€‚é ­ã®ä½ç½®ã‚’å®‰å®šã•ã›ã¾ã—ã‚‡ã†ã€‚",

    # å‚è€ƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    "shoulder_angle": "ä½“ãŒé–‹ãæ°—å‘³ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼ˆå‚è€ƒï¼‰ã€‚",
    "waist_rotation": "è…°ã®å›è»¢ãŒå°‘ã—å¼±ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆå‚è€ƒï¼‰ã€‚",
}

# èµ¤ä¸¸ã‚„æç”»å¯¾è±¡ï¼ˆå³åˆ©ãå›ºå®šï¼‰
FOCUS_LANDMARK = {
    "impact_height": 16,   # å³æ‰‹é¦–
    "elbow_angle": 14,    # å³è‚˜
    "body_sway": 24,      # å³è…°
}

# ================================
# Utility
# ================================

def to_pixel(p, w, h):
    return int(p[0] * w), int(p[1] * h)


def save_frame(video_path, idx, out_path):
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)

    ret, frame = cap.read()
    cap.release()

    if not ret:
        return None

    cv2.imwrite(out_path, frame)
    return frame


def smooth(x, w=5):
    return np.convolve(x, np.ones(w) / w, mode="same")


# ================================
# ğŸ¯ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¨å®šï¼ˆå³æ‰‹é¦–æœ€é«˜ç‚¹ï¼‰
# ================================

def detect_contact_frame(landmarks_3d):
    """
    æ¥è§¦ãƒ•ãƒ¬ãƒ¼ãƒ æ¨å®šï¼š
    ãƒ»å³æ‰‹é¦–ãŒæœ€é«˜ç‚¹ â†’ ä¸‹é™é–‹å§‹ã®ç›´å¾Œ
    """
    n = len(landmarks_3d)
    if n < 15:
        return int(n * 0.7)

    WRIST = 16

    wrist_y = np.array([landmarks_3d[i][WRIST][1] for i in range(n)])
    wrist_y = smooth(wrist_y, 5)

    peak = int(np.argmin(wrist_y))

    search_end = min(n - 1, peak + 8)
    best = peak

    for i in range(peak + 1, search_end):
        if wrist_y[i] - wrist_y[i - 1] > 0:
            best = i
            break

    return min(n - 1, best + 1)


# ================================
# ğŸ¨å›³è§£æç”»ãƒ«ãƒ¼ãƒ«
# ================================

def draw_focus(frame, focus, ux, uy, ix, iy):
    """
    focusã”ã¨ã«æç”»ã‚’å¤‰ãˆã‚‹
    """

    # æ‰“ç‚¹é«˜ã• â†’ æ¨ªãƒ©ã‚¤ãƒ³
    if focus == "impact_height":
        cv2.line(frame, (0, iy), (frame.shape[1], iy), (0, 255, 0), 3)
        cv2.line(frame, (0, uy), (frame.shape[1], uy), (0, 0, 255), 3)

    # è‚˜è§’åº¦ â†’ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ã‚¯
    elif focus == "elbow_angle":
        cv2.circle(frame, (ux, uy), 25, (0, 0, 255), 3)
        cv2.circle(frame, (ux, uy), 5, (0, 0, 255), -1)

        cv2.circle(frame, (ix, iy), 25, (0, 255, 0), 3)
        cv2.circle(frame, (ix, iy), 5, (0, 255, 0), -1)

    # ä½“è»¸ãƒ–ãƒ¬ â†’ ç¸¦ãƒ©ã‚¤ãƒ³
    elif focus == "body_sway":
        cv2.line(frame, (ix, 0), (ix, frame.shape[0]), (0, 255, 0), 3)
        cv2.line(frame, (ux, 0), (ux, frame.shape[0]), (0, 0, 255), 3)

    # ãã®ä»– â†’ å°ã•ã‚ä¸¸ã ã‘
    else:
        cv2.circle(frame, (ux, uy), 15, (0, 0, 255), -1)
        cv2.circle(frame, (ix, iy), 15, (0, 255, 0), -1)


# ================================
# ãƒ¡ã‚¤ãƒ³è§£æ
# ================================

def analyze_video(file_path):
    BASE_DIR = os.path.dirname(__file__)
    success_path = os.path.join(BASE_DIR, "success.mp4")

    # éª¨æ ¼æŠ½å‡º
    success_3d = extract_pose_landmarks(success_path)
    target_3d = extract_pose_landmarks(file_path)

    success_seq = normalize_pose(success_3d)
    target_seq = normalize_pose(target_3d)

    if len(success_seq) == 0 or len(target_seq) == 0:
        return {"menu": ["åŸºæœ¬ãƒ•ã‚©ãƒ¼ãƒ ç·´ç¿’"], "ai_text": "è§£æã§ãã¾ã›ã‚“ã§ã—ãŸ"}

    # ----------------
    # ã‚¹ã‚³ã‚¢è¨ˆç®—
    # ----------------
    dists = []
    for t in target_seq:
        d = np.linalg.norm(success_seq - t, axis=(1, 2))
        dists.append(np.min(d))

    score = int(max(0, min(100, 100 - np.mean(dists) * 28)))

    # ----------------
    # æŒ‡æ¨™è¨ˆç®—ï¼ˆå…¨éƒ¨æ®‹ã™ï¼‰
    # ----------------
    is_right = True

    shoulder_diff = np.mean(calculate_shoulder_angle(target_seq, is_right))
    elbow_diff = np.mean(calculate_elbow_angle(target_seq, is_right))
    sway_diff = np.mean(calculate_body_sway(target_seq))
    impact_h_diff = np.mean(calculate_impact_height(target_seq, is_right))

    # ----------------
    # weaknessåˆ¤å®š
    # ----------------
    weakness = {
        "impact_height": "low" if impact_h_diff < -0.15 else "ok",
        "elbow_angle": "too_bent" if elbow_diff < -20 else "ok",
        "body_sway": "unstable" if sway_diff > 0.03 else "ok",

        # å‚è€ƒæŒ‡æ¨™
        "shoulder_angle": "too_open" if shoulder_diff > 15 else "ok",
    }

    # ----------------
    # focusæ±ºå®šï¼ˆãƒ¡ã‚¤ãƒ³3ã¤ã ã‘ï¼‰
    # ----------------
    focus = "impact_height"
    for k in MAIN_FOCUS:
        if weakness.get(k) != "ok":
            focus = k
            break

    # ----------------
    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆ1å€‹ã ã‘ï¼‰
    # ----------------
    menu = [f"{FOCUS_LABELS[focus]}ã‚’æ”¹å–„ã™ã‚‹ç·´ç¿’ã‚’1ã¤ã ã‘ã‚„ã‚Šã¾ã—ã‚‡ã†"]

    # ----------------
    # å›³è§£ç”Ÿæˆ
    # ----------------
    out_dir = os.path.join(BASE_DIR, "..", "outputs")
    os.makedirs(out_dir, exist_ok=True)

    user_idx = detect_contact_frame(target_3d)
    ideal_idx = detect_contact_frame(success_3d)

    lid = FOCUS_LANDMARK[focus]

    cap = cv2.VideoCapture(file_path)
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    ux, uy = to_pixel(target_3d[user_idx][lid], w, h)
    ix, iy = to_pixel(success_3d[ideal_idx][lid], w, h)

    # ideal
    ideal_img = save_frame(success_path, ideal_idx, os.path.join(out_dir, "ideal.png"))
    if ideal_img is not None:
        draw_focus(ideal_img, focus, ix, iy, ix, iy)
        cv2.imwrite(os.path.join(out_dir, "ideal.png"), ideal_img)

    # user
    user_img = save_frame(file_path, user_idx, os.path.join(out_dir, "user.png"))
    if user_img is not None:
        draw_focus(user_img, focus, ux, uy, ix, iy)
        cv2.imwrite(os.path.join(out_dir, "user.png"), user_img)

    # ----------------
    # AIæ–‡ç« ï¼ˆçŸ­ãï¼‰
    # ----------------
    ai_text = f"æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã¯ã€Œ{FOCUS_LABELS[focus]}ã€ã§ã™ã€‚ã¾ãš1ã¤ã ã‘æ„è­˜ã—ã¾ã—ã‚‡ã†ï¼"

    return {
        "diagnosis": {
            "player": {"age": 13, "hand": "right", "serve_score": score},
            "weakness": weakness,
        },
        "menu": menu,
        "ai_text": ai_text,
        "ideal_image": "/outputs/ideal.png",
        "user_image": "/outputs/user.png",
        "focus_label": FOCUS_LABELS[focus],
        "message": FOCUS_MESSAGES.get(focus, "ãƒ•ã‚©ãƒ¼ãƒ ã‚’æ”¹å–„ã—ã¾ã—ã‚‡ã†ï¼"),
    }
